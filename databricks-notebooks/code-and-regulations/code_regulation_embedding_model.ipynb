{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "369ea041-ca73-41b7-8a4d-c502f8ed819f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/autoreload/discoverability/hook.py:72: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  module = self._original_builtins_import(name, *args, **kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5aa1bed51624870b4826ac2b474911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4545a52503c14481a741003f344c051d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908d2564c50e48a48a151ff44d279c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b840a41b11a8499f9a39af333c689a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5659e198b234d1a82cb375da95c9ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd25aeabbda544ea9915d17c9f39f748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1b379423604949ac5277cb894abff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a9127ab86946a3be3101562952feff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7413d5223ff84239a1a529a65daa6d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bbf459ce0347229a620b7837ca3ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068cf8ca9e434dc6ae7b760fc2f193a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145bc1e09da149ab8176159a5b1f8003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'llm_workspace.default.hugging_face_sentence_transformer_model'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd59e9cb51ec410ba607592b62eca315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'llm_workspace.default.hugging_face_sentence_transformer_model'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20170879acbd4af79d558708ed24778f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/23 06:06:03 INFO mlflow.tracking._tracking_service.client: 🏃 View run all-MiniLM-L6-v2-run at: https://dbc-077f5204-3af4.cloud.databricks.com/ml/experiments/26fc5ff7060643a7a96d401413b2ab0e/runs/403ec23637954d94b02cabcdab138bfa.\n2024/10/23 06:06:03 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dbc-077f5204-3af4.cloud.databricks.com/ml/experiments/26fc5ff7060643a7a96d401413b2ab0e.\n"
     ]
    }
   ],
   "source": [
    "# create the sentence transformer (can skip if model exist)\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class SentenceTransformerModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        # Load the sentence transformer model\n",
    "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')  # Use your model name here\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        def encode_text(text):\n",
    "            try:\n",
    "                return self.model.encode(text, show_progress_bar=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encoding text: {text}. Error: {str(e)}\")\n",
    "                return np.zeros(384)  # Assuming embedding size is 384\n",
    "\n",
    "        # Apply the model to the input DataFrame\n",
    "        text_series = model_input.iloc[:, 0]  # Assuming the first column is the text\n",
    "        embeddings = text_series.apply(encode_text)\n",
    "        return pd.DataFrame(embeddings.tolist())\n",
    "\n",
    "# Create sample input and output\n",
    "sample_input = pd.DataFrame({'text': [\"This is a sample sentence\"]})\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Create sample output by encoding the text\n",
    "sample_output = pd.DataFrame([model.encode(\"This is a sample sentence\").tolist()])\n",
    "\n",
    "# Infer the model signature\n",
    "from mlflow.models.signature import infer_signature\n",
    "signature = infer_signature(sample_input, sample_output)\n",
    "\n",
    "run_name=\"all-MiniLM-L6-v2-run\"\n",
    "\n",
    "# Log the model to MLflow\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"hugging_face_sentence_transformer_model\",\n",
    "        python_model=SentenceTransformerModel(),\n",
    "        input_example=sample_input,\n",
    "        signature=signature,\n",
    "        registered_model_name=\"hugging_face_sentence_transformer_model\"  # Specify the name in the registry\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "/Workspace/Shared/genai-databricks-hackathon-2024/databricks-notebooks/databricks_base_environment.yml",
    "client": "1",
    "dependencies": [
     "sentence-transformers",
     "mlflow"
    ]
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "code_regulation_embedding_model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
